{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intent_Detection_LSTM (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09Vxn7338rLp",
        "colab_type": "text"
      },
      "source": [
        "#Intent Classification using LSTM \n",
        "This use-case provides a demo of how LSTM can be used for Intent classification in texts. \n",
        "\n",
        "##Workflow:\n",
        "\n",
        "1.   Understanding the problem\n",
        "2.   Reading the data and understanding it\n",
        "3.   Data Preprocessing\n",
        "4.   Build LSTM model\n",
        "5.   Train & Evaluate the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYTbGtop9jP1",
        "colab_type": "text"
      },
      "source": [
        "##1. Understanding the problem\n",
        "Intent Classification is the automated association of text to a specific intention. For example: Let's say you are writing an email to one of the Airlines and the text of the same is 'Can you please cancel my ticket with PNR 123456'. The intent of the customer here is 'Cancellation of Air Ticket'.\n",
        "\n",
        "The idea of this use case to introduce the concept of Intent classification and how can LSTM be used to solve this. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEN-kTBx_4sC",
        "colab_type": "text"
      },
      "source": [
        "###Import the necessary libraries\n",
        "Please load the following packages before you proceed further. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8k38KZeu8uUS",
        "colab_type": "code",
        "outputId": "c1ef4df1-0f6b-4e61-8da1-60be0c0ece5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import nltk\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder as oneHot\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "from string import punctuation\n",
        "from nltk.stem import PorterStemmer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.layers import BatchNormalization, Dropout, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy as cce\n",
        "from tensorflow.keras.activations import relu, softmax\n",
        "from tensorflow.keras.initializers import he_uniform, glorot_uniform\n",
        "from tensorflow.keras.metrics import AUC\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFjqYhVvAY8i",
        "colab_type": "text"
      },
      "source": [
        "##2. Collecting the Data\n",
        "The ATIS(Air Travel Information System) data is a rich corpus that contains natural language text used by general public to book flight tickets, enquire about flight timings, prices etc. \n",
        "\n",
        "The Train and test data can be downloaded from https://www.kaggle.com/hassanamin/atis-airlinetravelinformationsystem\n",
        "\n",
        "There are 2 columns in each of the above datasets. First column is 'target' which is the output we will be classifying and second column is 'text' which is the user input asking for queries related to flights. \n",
        "\n",
        "Basically 'target' is the intent of the customer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXCF5zWiwcYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Read the train and test datasets with column names as target and text\n",
        "train= pd.read_csv('atis_intents_train.csv',\n",
        "                       names= [\"target\", \"text\"])\n",
        "\n",
        "test= pd.read_csv('atis_intents_test.csv',\n",
        "                       names= [\"target\", \"text\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcA1sbFmrc2c",
        "colab_type": "text"
      },
      "source": [
        "####This is how the data looks like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcBN6Hn2rhjD",
        "colab_type": "code",
        "outputId": "b77182a2-2fe4-4978-8612-9fa47f330be1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "train.head(10) #Get Top 10 rows from train dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>i want to fly from boston at 838 am and arriv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>what flights are available from pittsburgh to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>atis_flight_time</td>\n",
              "      <td>what is the arrival time in san francisco for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>atis_airfare</td>\n",
              "      <td>cheapest airfare from tacoma to orlando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>atis_airfare</td>\n",
              "      <td>round trip fares from pittsburgh to philadelp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>i need a flight tomorrow from columbus to min...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>atis_aircraft</td>\n",
              "      <td>what kind of aircraft is used on a flight fro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>show me the flights from pittsburgh to los an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>all flights from boston to washington</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>atis_ground_service</td>\n",
              "      <td>what kind of ground transportation is availab...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                target                                               text\n",
              "0          atis_flight   i want to fly from boston at 838 am and arriv...\n",
              "1          atis_flight   what flights are available from pittsburgh to...\n",
              "2     atis_flight_time   what is the arrival time in san francisco for...\n",
              "3         atis_airfare            cheapest airfare from tacoma to orlando\n",
              "4         atis_airfare   round trip fares from pittsburgh to philadelp...\n",
              "5          atis_flight   i need a flight tomorrow from columbus to min...\n",
              "6        atis_aircraft   what kind of aircraft is used on a flight fro...\n",
              "7          atis_flight   show me the flights from pittsburgh to los an...\n",
              "8          atis_flight              all flights from boston to washington\n",
              "9  atis_ground_service   what kind of ground transportation is availab..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQFpMc7pr5My",
        "colab_type": "text"
      },
      "source": [
        " Check the number of intents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63HCDQh2r4Ue",
        "colab_type": "code",
        "outputId": "bcf11920-70eb-44a9-8e5f-f0fd32741551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "train['target'].value_counts() #Get counts of different types of target variable in train data. We will not be using this anywhere but it is just for the overview of the data.  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "atis_flight            3666\n",
              "atis_airfare            423\n",
              "atis_ground_service     255\n",
              "atis_airline            157\n",
              "atis_abbreviation       147\n",
              "atis_aircraft            81\n",
              "atis_flight_time         54\n",
              "atis_quantity            51\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vaan11BFwPUM",
        "colab_type": "text"
      },
      "source": [
        "### 3. Preprocessing the Data\n",
        "We will be doing the following preprocessing steps to get the desired format of the data. \n",
        "\n",
        "1. Perform One Hot Encoding on the target variable of both train & test datasets.\n",
        "2. Convert the text into lower case.\n",
        "3. Tokenize the words.\n",
        "4. Remove stop words.\n",
        "5. Perform stemming & normalization.\n",
        "6. Convert texts into sequences.\n",
        "7. Pad the sequences.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ASGgSyGwzgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encode_target= oneHot().fit(np.array(train.target).reshape(-1,1)) #We perform one hot encoding on the target variable to convert into a matrix of 0s and 1s. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YY1ZPSK1CjEP",
        "colab_type": "text"
      },
      "source": [
        "Perform One Hot Encoding on the target variable. The output of this step would be an array with 0s and 1s. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fN8Y4bOzXk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_target_encoded= encode_target.transform(np.array(train.target).reshape(-1,1)).toarray()\n",
        "test_target_encoded= encode_target.transform(np.array(test.target).reshape(-1,1)).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2HirMzwDf5q",
        "colab_type": "text"
      },
      "source": [
        "Convert text to lower case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiUYFX5Ywcnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train[\"text\"]= train.text.map(lambda l: l.lower())\n",
        "test[\"text\"]= test.text.map(lambda l: l.lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qinvp54EDer0",
        "colab_type": "text"
      },
      "source": [
        "Next step is to tokenize the text. We use word_tokenize function from nltk library for this purpose. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJR50ShUwcht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train[\"text\"]= train.text.map(word_tokenize)\n",
        "test[\"text\"]= test.text.map(word_tokenize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS2kgyqqEN1R",
        "colab_type": "code",
        "outputId": "b7ef8a50-627d-4aaf-e9c9-1a67fe598ab6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "#Output of the above exercise looks like this\n",
        "train[\"text\"]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [i, want, to, fly, from, boston, at, 838, am, ...\n",
              "1       [what, flights, are, available, from, pittsbur...\n",
              "2       [what, is, the, arrival, time, in, san, franci...\n",
              "3          [cheapest, airfare, from, tacoma, to, orlando]\n",
              "4       [round, trip, fares, from, pittsburgh, to, phi...\n",
              "                              ...                        \n",
              "4829    [what, is, the, airfare, for, flights, from, d...\n",
              "4830    [do, you, have, any, flights, from, denver, to...\n",
              "4831    [which, airlines, fly, into, and, out, of, den...\n",
              "4832    [does, continental, fly, from, boston, to, san...\n",
              "4833    [is, there, a, delta, flight, from, denver, to...\n",
              "Name: text, Length: 4834, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqBeYgcwEez3",
        "colab_type": "text"
      },
      "source": [
        "Eliminate stop words. 'english' dictionary from nltk.corpus library is used for this purpose. We also remove punctuation along with the removal of stop words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlsQpXeOwcfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_data_rm_stop(strings, stop_list):\n",
        "    sw= [str for str in strings if str not in stop_list]\n",
        "    return sw\n",
        "\n",
        "stop_words= stopwords.words(\"english\")\n",
        "rm_punc_stop= list(set(punctuation))+ stop_words #Remove punctuation and stop words\n",
        "\n",
        "train[\"text\"]= train.text.map(lambda dataframe: clean_data_rm_stop(dataframe, rm_punc_stop))\n",
        "test[\"text\"]= test.text.map(lambda dataframe: clean_data_rm_stop(dataframe, rm_punc_stop))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUfp5HlrEd_z",
        "colab_type": "text"
      },
      "source": [
        "Stemming & Normalizing\n",
        "\n",
        "\n",
        "*   Stemming helps in reducing the word to the root form.\n",
        "*   Normalizing is the process of transforming text into a standard form. Eg: Gud will be converted to good etc.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTyFrktRwcch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(text):\n",
        "    return \" \".join(text)\n",
        "\n",
        "#We use PorterStemmer function from nltk.stem library.\n",
        "stem_func= PorterStemmer()\n",
        "\n",
        "train[\"text\"]= train.text.map(lambda s: [stem_func.stem(x) for x in s])\n",
        "train[\"text\"]= train.text.apply(normalize)\n",
        "\n",
        "test[\"text\"]= test.text.map(lambda s: [stem_func.stem(x) for x in s])\n",
        "test[\"text\"]= test.text.apply(normalize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wp1q6YAGneR",
        "colab_type": "text"
      },
      "source": [
        "Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjiTh4B-yyKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We use Tokenizer from tensorflow.keras.preprocessing.text library\n",
        "num_words=10000\n",
        "text_tokenizer= Tokenizer(num_words)\n",
        "text_tokenizer.fit_on_texts(train.text) #fit_on_texts - creates the vocabulary index based on word frequency.\n",
        "\n",
        "tokenized_train_data= text_tokenizer.texts_to_sequences(train.text) #Converting texts to sequences\n",
        "tokenized_test_data= text_tokenizer.texts_to_sequences(test.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwzRRO70Hk3S",
        "colab_type": "text"
      },
      "source": [
        "Then, we pad the sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z_dRUZay3KD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We use pad_sequences from tensorflow.keras.preprocessing.sequence library\n",
        "train_data= pad_sequences(tokenized_train_data, maxlen= 20, padding= \"pre\")\n",
        "test_data= pad_sequences(tokenized_test_data, maxlen= 20, padding= \"pre\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HT2iJpbHivt",
        "colab_type": "text"
      },
      "source": [
        "Let's build a 3 dim array. The dimensions are samples, steps and unique words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwM8Y2uEy3Vx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform_matrix(data, tokenizer):\n",
        "    output_shape_mat= [data.shape[0],\n",
        "                  data.shape[1],\n",
        "                  tokenizer.word_index.keys().__len__()] #Three dimensional matrix with samples, steps and number of uniques words as each dimension.\n",
        "    results_data= np.zeros(output_shape_mat) #creates new array with given dimensions.\n",
        "    \n",
        "    for i in range(data.shape[0]):\n",
        "        for j in range(data.shape[1]):\n",
        "            results_data[i, j, data[i,j]-1]= 1 # In this for loop, we are looping over the shape of the training & test data and assigning the cell of above created zero matrix to 1. We are performing encoding on the unique words to obtain the transformation matrix\n",
        "    return results_data\n",
        "\n",
        "trans_matrix_train= transform_matrix(train_data, text_tokenizer) #This will be the matrix on which the lstm model is applied\n",
        "trans_matrix_test= transform_matrix(test_data, text_tokenizer) #This will be the matrix on which the model is tested"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSG06CjZMFdw",
        "colab_type": "text"
      },
      "source": [
        "### 4. Build LSTM Model\n",
        "\n",
        "Build a class lstm_model_class that has three methods(methods are similar to functions) in a class, they are:\n",
        "\n",
        "\n",
        "\n",
        "1.   Build a lstm model \n",
        "2.   Train the created lstm model on the train data\n",
        "3.   Predict the output on the train data\n",
        "\n",
        "Note: Building a Class with 3 methods helps in tying all these three functions to the same object at the same instance. \n",
        "\n",
        "Process of Building a LSTM Model:\n",
        "\n",
        "\n",
        "\n",
        "1.   Build an embedded layer with dimensions as number of steps and input dimensions. \n",
        "2.   Build an LSTM layer with number of steps equal to memory units.  \n",
        "3.   Then, build a dense layer which is fully connected layer that represents a matrix vector multiplication. \n",
        "4.   Apply the relu function after normalization and scaling of the activations. This is the standard activation function used. \n",
        "5.   Finally, build the output layer.\n",
        "\n",
        "Note: \n",
        "1. activation function for multi-class classification problem - softmax\n",
        "2. loss function is categorical cross entropy. \n",
        "3. performace metric - Area under the curve(AUC)\n",
        "4. optimizer would be the Adam optimizer. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qfSIpcHy3a2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class lstm_model_class(object):\n",
        "    def build_lstm_model(self,input_dimensions, op_shape, num_steps, dropout_rate, kernel_reg, bias_reg):\n",
        "      ip_layer= Input(shape= (num_steps, input_dimensions)) #Define embedded layer with shape as number of steps and input dimensions. Note that both these are input variables to the model.\n",
        "        \n",
        "      lstm_model= LSTM(units= num_steps)(ip_layer) #Make the LSTM layer with number of steps as memory units\n",
        "      dense_layer_1= Dense(op_shape, kernel_initializer= he_uniform(), #he_uniform draws samples in uniform distribution with -inf to +inf as range.\n",
        "                   bias_initializer= \"zeros\", \n",
        "                   kernel_regularizer= l2(l= kernel_reg),\n",
        "                   bias_regularizer= l2(l= bias_reg))(lstm_model) # Create the  Dense layer which is the regular deeply connected layer \n",
        "      int_layer= BatchNormalization()(dense_layer_1) #Normalize and scale activations of the dense layer with BatchNormalization function\n",
        "      int_layer= relu(int_layer) #This applies the rectified linear unit activation function\n",
        "      int_layer= Dropout(rate= dropout_rate)(int_layer) #Dropout is used to define Dropout layer that sets input units to 0 with a frequency. Here it is dropout_rate\n",
        "      output_1= Dense(op_shape, kernel_initializer= glorot_uniform(), #glorot_uniform draws samples in uniform distribution with stddev = sqrt(2 / (fan_in + fan_out)) fan_in is num of units in weight tensor and fan_out is num of output units\n",
        "             bias_initializer= \"zeros\", \n",
        "             kernel_regularizer= l2(l= kernel_reg), \n",
        "             bias_regularizer= l2(l= bias_reg))(dense_layer_1) # Create another dense layer which is the output of the model.\n",
        "      output_1= BatchNormalization()(output_1) #Normalize and scale activations of the dense layer with BatchNormalization function\n",
        "      final_output= softmax(output_1, axis= 1) \n",
        "        \n",
        "      loss_func= cce() # Since it is a multi-class classification problem, categorical crossentropy(cce) is used as the loss function\n",
        "      perf_metrics= AUC() #our performance metric will be area under the curve\n",
        "      optimizer= Adam() #we shall use Adam optimizer as our optimizer\n",
        "      self.final_model= Model(inputs= [ip_layer], outputs= [final_output]) #Build the model with input and output layers\n",
        "      self.final_model.compile(optimizer= optimizer, loss= loss_func, metrics= [perf_metrics]) #Compiling the keras model\n",
        "\n",
        "    def train_lstm_model(self,x, y, valid_split, ep):\n",
        "      self.final_model.fit(x, y, validation_split= valid_split, epochs= ep) #Create the train model\n",
        "\n",
        "\n",
        "    def predict_lstm_model(self,x):\n",
        "      return self.final_model.predict(x)    #Create the predict model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRmkHRRUU5Uv",
        "colab_type": "text"
      },
      "source": [
        "Build the model on the necessary inputs.\n",
        "We define the number of steps as the , output shape and input dimensio appropriately. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v41QY3ly3Zb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "steps= trans_matrix_train.shape[1] #Define the number of steps is usually the number of steps in the train data.\n",
        "input_dim= trans_matrix_train.shape[2] #Input dimension. Number of unique words in the train data \n",
        "output_shape= train_target_encoded.shape[1] #Output shape. Usually the same number as the number of classes in the target variable. Here we have 8. \n",
        "final_model= lstm_model_class()\n",
        "final_model.build_lstm_model(input_dimensions= input_dim,\n",
        "                  op_shape= output_shape,\n",
        "                  num_steps= steps, \n",
        "                  dropout_rate= 0.5, # Meaning 1 in 2 inputs will be randomly executed. \n",
        "                  bias_reg= 0.3, # Reduce the bias in the model\n",
        "                  kernel_reg= 0.3) #Reduce the weights excluding bias. \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0HQ71DqWA_p",
        "colab_type": "text"
      },
      "source": [
        "### 5. Train & Evaluate the model\n",
        "In our last step, we will train and evaluate the model and check the performance metrics. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKS5QDZcy3UH",
        "colab_type": "code",
        "outputId": "2f24338b-3c15-4759-8923-2a1022996a7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "final_model.train_lstm_model(trans_matrix_train, train_target_encoded,\n",
        "           0.2, 60) #Model takes train data, train target variable, validation split(here it is 80:20) and number of epochs. "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "121/121 [==============================] - 2s 13ms/step - loss: 7.2804 - auc: 0.7257 - val_loss: 5.8829 - val_auc: 0.6351\n",
            "Epoch 2/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 4.1178 - auc: 0.9361 - val_loss: 3.4945 - val_auc: 0.9867\n",
            "Epoch 3/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 2.4641 - auc: 0.9746 - val_loss: 2.5842 - val_auc: 0.9226\n",
            "Epoch 4/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 1.6020 - auc: 0.9844 - val_loss: 1.4742 - val_auc: 0.9943\n",
            "Epoch 5/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 1.1521 - auc: 0.9908 - val_loss: 0.9134 - val_auc: 0.9963\n",
            "Epoch 6/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.9257 - auc: 0.9938 - val_loss: 0.6942 - val_auc: 0.9979\n",
            "Epoch 7/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.7929 - auc: 0.9952 - val_loss: 0.6916 - val_auc: 0.9956\n",
            "Epoch 8/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.6836 - auc: 0.9967 - val_loss: 0.6047 - val_auc: 0.9946\n",
            "Epoch 9/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.6265 - auc: 0.9978 - val_loss: 0.5225 - val_auc: 0.9971\n",
            "Epoch 10/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.5694 - auc: 0.9977 - val_loss: 0.4863 - val_auc: 0.9959\n",
            "Epoch 11/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.5111 - auc: 0.9986 - val_loss: 0.4461 - val_auc: 0.9946\n",
            "Epoch 12/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.4760 - auc: 0.9986 - val_loss: 0.4722 - val_auc: 0.9933\n",
            "Epoch 13/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.4369 - auc: 0.9985 - val_loss: 0.3985 - val_auc: 0.9961\n",
            "Epoch 14/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.4131 - auc: 0.9990 - val_loss: 0.3889 - val_auc: 0.9947\n",
            "Epoch 15/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.3834 - auc: 0.9989 - val_loss: 0.3495 - val_auc: 0.9959\n",
            "Epoch 16/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.3602 - auc: 0.9989 - val_loss: 0.3221 - val_auc: 0.9954\n",
            "Epoch 17/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.3383 - auc: 0.9993 - val_loss: 0.3535 - val_auc: 0.9979\n",
            "Epoch 18/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.3251 - auc: 0.9992 - val_loss: 0.3052 - val_auc: 0.9943\n",
            "Epoch 19/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.3059 - auc: 0.9994 - val_loss: 0.3031 - val_auc: 0.9944\n",
            "Epoch 20/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.2970 - auc: 0.9994 - val_loss: 0.2895 - val_auc: 0.9943\n",
            "Epoch 21/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.2737 - auc: 0.9996 - val_loss: 0.2777 - val_auc: 0.9946\n",
            "Epoch 22/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.2605 - auc: 0.9997 - val_loss: 0.2674 - val_auc: 0.9967\n",
            "Epoch 23/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.2537 - auc: 0.9995 - val_loss: 0.2519 - val_auc: 0.9953\n",
            "Epoch 24/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.2391 - auc: 0.9996 - val_loss: 0.2504 - val_auc: 0.9950\n",
            "Epoch 25/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.2284 - auc: 0.9997 - val_loss: 0.2517 - val_auc: 0.9947\n",
            "Epoch 26/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.2231 - auc: 0.9996 - val_loss: 0.2403 - val_auc: 0.9952\n",
            "Epoch 27/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.2127 - auc: 0.9997 - val_loss: 0.2336 - val_auc: 0.9954\n",
            "Epoch 28/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.2064 - auc: 0.9998 - val_loss: 0.2217 - val_auc: 0.9964\n",
            "Epoch 29/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.2003 - auc: 0.9997 - val_loss: 0.2137 - val_auc: 0.9961\n",
            "Epoch 30/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1948 - auc: 0.9997 - val_loss: 0.2153 - val_auc: 0.9962\n",
            "Epoch 31/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1889 - auc: 0.9998 - val_loss: 0.2108 - val_auc: 0.9958\n",
            "Epoch 32/60\n",
            "121/121 [==============================] - 1s 9ms/step - loss: 0.1831 - auc: 0.9997 - val_loss: 0.2085 - val_auc: 0.9958\n",
            "Epoch 33/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1763 - auc: 0.9997 - val_loss: 0.2139 - val_auc: 0.9952\n",
            "Epoch 34/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1727 - auc: 0.9998 - val_loss: 0.1969 - val_auc: 0.9966\n",
            "Epoch 35/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1666 - auc: 0.9998 - val_loss: 0.1971 - val_auc: 0.9974\n",
            "Epoch 36/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1619 - auc: 0.9997 - val_loss: 0.1970 - val_auc: 0.9971\n",
            "Epoch 37/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1584 - auc: 0.9999 - val_loss: 0.1929 - val_auc: 0.9959\n",
            "Epoch 38/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1532 - auc: 0.9998 - val_loss: 0.1869 - val_auc: 0.9962\n",
            "Epoch 39/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1491 - auc: 0.9999 - val_loss: 0.1851 - val_auc: 0.9962\n",
            "Epoch 40/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1436 - auc: 0.9999 - val_loss: 0.1790 - val_auc: 0.9971\n",
            "Epoch 41/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1397 - auc: 0.9999 - val_loss: 0.1791 - val_auc: 0.9972\n",
            "Epoch 42/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1369 - auc: 0.9998 - val_loss: 0.1696 - val_auc: 0.9968\n",
            "Epoch 43/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1323 - auc: 0.9999 - val_loss: 0.1667 - val_auc: 0.9968\n",
            "Epoch 44/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1305 - auc: 1.0000 - val_loss: 0.1665 - val_auc: 0.9963\n",
            "Epoch 45/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1288 - auc: 0.9999 - val_loss: 0.1726 - val_auc: 0.9954\n",
            "Epoch 46/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1247 - auc: 0.9999 - val_loss: 0.1623 - val_auc: 0.9958\n",
            "Epoch 47/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1204 - auc: 0.9999 - val_loss: 0.1611 - val_auc: 0.9969\n",
            "Epoch 48/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1188 - auc: 0.9999 - val_loss: 0.1555 - val_auc: 0.9963\n",
            "Epoch 49/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1150 - auc: 0.9999 - val_loss: 0.1568 - val_auc: 0.9963\n",
            "Epoch 50/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1131 - auc: 0.9999 - val_loss: 0.1850 - val_auc: 0.9977\n",
            "Epoch 51/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1148 - auc: 1.0000 - val_loss: 0.1697 - val_auc: 0.9968\n",
            "Epoch 52/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1145 - auc: 0.9999 - val_loss: 0.1500 - val_auc: 0.9960\n",
            "Epoch 53/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1036 - auc: 0.9999 - val_loss: 0.1485 - val_auc: 0.9965\n",
            "Epoch 54/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1037 - auc: 0.9999 - val_loss: 0.1422 - val_auc: 0.9970\n",
            "Epoch 55/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1016 - auc: 1.0000 - val_loss: 0.1455 - val_auc: 0.9960\n",
            "Epoch 56/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1021 - auc: 0.9999 - val_loss: 0.1454 - val_auc: 0.9964\n",
            "Epoch 57/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.0989 - auc: 1.0000 - val_loss: 0.1430 - val_auc: 0.9970\n",
            "Epoch 58/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.0972 - auc: 1.0000 - val_loss: 0.1445 - val_auc: 0.9966\n",
            "Epoch 59/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.1007 - auc: 1.0000 - val_loss: 0.1559 - val_auc: 0.9950\n",
            "Epoch 60/60\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.0949 - auc: 0.9999 - val_loss: 0.1498 - val_auc: 0.9959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BvoHJ2z0ZoJ",
        "colab_type": "code",
        "outputId": "0f060d3e-add7-4f0b-b7c6-9e5189992211",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "pred_train= encode_target.inverse_transform(final_model.predict_lstm_model(trans_matrix_train)) #Predict on the train matrix and look at the performance\n",
        "print(classification_report(train.target, pred_train)) #Print the classification report"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                     precision    recall  f1-score   support\n",
            "\n",
            "  atis_abbreviation       0.96      1.00      0.98       147\n",
            "      atis_aircraft       0.97      0.96      0.97        81\n",
            "       atis_airfare       0.99      0.99      0.99       423\n",
            "       atis_airline       0.98      0.96      0.97       157\n",
            "        atis_flight       1.00      1.00      1.00      3666\n",
            "   atis_flight_time       0.98      0.94      0.96        54\n",
            "atis_ground_service       1.00      1.00      1.00       255\n",
            "      atis_quantity       1.00      1.00      1.00        51\n",
            "\n",
            "           accuracy                           0.99      4834\n",
            "          macro avg       0.98      0.98      0.98      4834\n",
            "       weighted avg       0.99      0.99      0.99      4834\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nueVLp5cYAOa",
        "colab_type": "text"
      },
      "source": [
        "F1 and weighted avg are excellent. We can now move to implement this model on test data and see how it is performing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pynraJ0I0ZwG",
        "colab_type": "code",
        "outputId": "949a7f59-485c-4770-c62a-1dce0dcaef13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "pred_test= encode_target.inverse_transform(final_model.predict_lstm_model(trans_matrix_test)) #Predict on the test data\n",
        "print(classification_report(test.target, pred_test)) #Print the classification report"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                     precision    recall  f1-score   support\n",
            "\n",
            "  atis_abbreviation       0.80      1.00      0.89        33\n",
            "      atis_aircraft       0.83      0.56      0.67         9\n",
            "       atis_airfare       0.98      1.00      0.99        48\n",
            "       atis_airline       0.97      0.76      0.85        38\n",
            "        atis_flight       0.99      0.99      0.99       632\n",
            "   atis_flight_time       0.50      1.00      0.67         1\n",
            "atis_ground_service       1.00      0.94      0.97        36\n",
            "      atis_quantity       0.43      1.00      0.60         3\n",
            "\n",
            "           accuracy                           0.97       800\n",
            "          macro avg       0.81      0.91      0.83       800\n",
            "       weighted avg       0.98      0.97      0.97       800\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jczYwlA88qF3",
        "colab_type": "text"
      },
      "source": [
        "F1 and weighted avg are excellent. We can settle with this model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6Uc3lq1YisX",
        "colab_type": "text"
      },
      "source": [
        "### Next Steps\n",
        "\n",
        "\n",
        "*   Try changing some of the parameters and see if there could be any change in the performance metrics. \n",
        "\n"
      ]
    }
  ]
}